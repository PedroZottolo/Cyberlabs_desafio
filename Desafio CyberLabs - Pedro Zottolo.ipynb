{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio - Pedro Zottolo\n",
    "\n",
    "Vamos utilizar dos mesmos recursos demonstrados no Git(https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) e vejamos o resultado da classificação desta Net. \n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar a base de dados do MNIST para a classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento vemos quais \"pastas\" possuem no path, iremos seleciona-las mais tarde para os dados de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('testing'),Path('training')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema queremos classificar apenas os dígitos 0 e 5, ou seja, dentre as pastas mostradas acima selecionaremos os paths correspondentes para o aprendizado de máquina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = (path/'training'/'0').ls().sorted()\n",
    "cinco = (path/'training'/'5').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, iremos criar os tensores das nossas imagens, contendo todos os zeros e cincos em cada um dos tensores,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5923"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensores_z = [tensor(Image.open(o)) for o in zero]\n",
    "tensores_c = [tensor(Image.open(o)) for o in cinco]\n",
    "len(tensores_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisaremos normalizar os dados de cada imagem, isto significa, como os valores estão entre 0 e 1 precisamos dividir os pixels pelo valor máximo deles, neste caso 255, sendo assim:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_z = torch.stack(tensores_z).float()/255\n",
    "stacked_c = torch.stack(tensores_c).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de treino\n",
    "\n",
    "Feita a parte de divisão e seleceção de dados para o nosso problema, iremos criar nossas variáveis para o aprendizado, isto é, definir nossas variáveis de treino e de validação: train_x, train_y, valid_x e valid_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_z, stacked_c]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11344, 784]), torch.Size([11344, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1]*len(zero) + [0]*len(cinco)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento, identificaremos os zeros com 1 e os cincos como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tens_v = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'0').ls()])\n",
    "z_tens_v = z_tens_v.float()/255\n",
    "c_tens_v = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'5').ls()])\n",
    "c_tens_v = c_tens_v.float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([z_tens_v, c_tens_v]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(z_tens_v) + [0]*len(c_tens_v)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos criar um DataLoader de cada Dataset, tanto do treino quanto da validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "xb,yb = first(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parâmetros de inicialização e Funções\n",
    "\n",
    "Para que o nosso modelo, queremos ter parâmetros aleatórios para a computação dos dados e funções que ajudem no aprendizados, ou seja, funções que sejam ativadas dado algum parâmetro de inicialização.\n",
    "\n",
    "Primeiramente, vamos definir nossa função que irá inicializar nossos parâmetros de forma aleatória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora nossas funções de ativação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo de aprendizado será uma Net simples, dado que Neutral Networks possuem taxa de erros baixas [1] e que o nosso problema será de classificação de dois algarismos, podemos definir um modelo mais simples e ir vendo suas fraquezas e como melhorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então o Simple Net será dado por"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos melhorar sempre a nossa perfomance de aprendizado, queremos que nosso programa aprenda de maneira otimizada também, para isso selecionaremos a melhor taxa de Learning Error, para isso escolhemos lr = 0.1[2]. Precisamos também otimizar o número de Epoch, como mostrado em [3] para esse problema o número de Epoch é bom entre 30 e 100, como estamos trabalhando com um Dataset grande, na grandeza de 6000 dados, e com uma Loss Function diferente da que é mostrada podemos escolher epoch = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.360193</td>\n",
       "      <td>0.502902</td>\n",
       "      <td>0.476496</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221305</td>\n",
       "      <td>0.450967</td>\n",
       "      <td>0.497329</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.316969</td>\n",
       "      <td>0.682158</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088143</td>\n",
       "      <td>0.207040</td>\n",
       "      <td>0.822650</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061772</td>\n",
       "      <td>0.141028</td>\n",
       "      <td>0.899038</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047329</td>\n",
       "      <td>0.102775</td>\n",
       "      <td>0.927885</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039047</td>\n",
       "      <td>0.079677</td>\n",
       "      <td>0.946581</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>0.064690</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030786</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.963675</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.028552</td>\n",
       "      <td>0.047091</td>\n",
       "      <td>0.968483</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026913</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.971688</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>0.974893</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>0.975962</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.029704</td>\n",
       "      <td>0.977030</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.027973</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.982372</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>0.024162</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.023206</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.983440</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.983974</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.019435</td>\n",
       "      <td>0.020923</td>\n",
       "      <td>0.984509</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.985043</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.018820</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.019256</td>\n",
       "      <td>0.985043</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.986645</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.986645</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.017314</td>\n",
       "      <td>0.017312</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>0.016468</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016223</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.015778</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.015201</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.014153</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.988248</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(50, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado\n",
    "\n",
    "Vemos que a net simples desempenhou um bom resultado, 98,82%,  na classificação de 0 e 5. Alguns passos foram modificados e estudados a partir das referêcias abaixo, para atingir o melhor resultado possível, outras funções de Loss ou de Otimizer podiam ser diferentes como Adabound [4], como também outros modelos a serem tratados Extended Minimal e LeNet5 [5], dentre outros [6]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[1] Baldominos, A.; Saez, Y.; Isasi, P. A Survey of Handwritten Character Recognition with MNIST and EMNIST. Appl. Sci. 2019, 9, 3169. https://doi.org/10.3390/app9153169\n",
    "[2] Smith, L. Cyclical Learning Rates for Training Neural Networks. arXiv:1506.01186 [cs.CV]\n",
    "[3] Afaq, S.; Rao, S. Significance Of Epochs On Training A Neural Network. International Journal of Scientific & Technology Research Volume 9, Issue 06, June 2020\n",
    "[4] Luo, L.; Xiong, Y.; Liu, Y.; Sun, X. Adaptative Gradient Methods with Dynamic Bound of Learning Rate. ICLR 2019\n",
    "[5] Teow, M. Understanding Convolutional Neural Networks Using A Minimal Model for Handwritten Digit Recognition. 978-1-5386-0846-3/17/31.00 ©2017 IEEE\n",
    "[6] McDonnell, M.; Tissera, M.; Vladusich, T.; van Schaik, A.; Tapson, J. Fast, simple and accurate handwritten digit classification by training shallow neural network classifiers with the 'extreme learning machine' algorithm. arXiv:1412.8307v2 [cs.NE] 22 Jul 2015\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
